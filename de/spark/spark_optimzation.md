## Spark Optimization

### Columnar Storage

![image.png](https://github.com/user-attachments/assets/077df482-73a5-413a-bebd-196720017e0c)

- 동일한 Type의 Data를 함께 저장해서 압축률이 좋다.
- 일부 열만 사용하는 쿼리를 날릴 경우 효과적이다.
- 하나의 컬럼에 집계 쿼리를 날릴 경우 효과적이다.
- `Predicate PushDown`:
    - 데이터를 읽고 나서 처리하는 방식이 아니라, 데이터를 읽기 전에 처리하는 방식
    - age가 30보다 적은 row를 추출하고 싶다면, 원래는 DataFrame Load → filter 과정이지만, 애당초에 가장 시간이 많이 걸리는 I/O 작업에서 age가 30보다 적으면 **`읽지를 않는 방법`**을 통해 효율적으로 처리를 수행하는 방식

### Py4J는 무엇인가?

- Py4J는 파이썬과 자바 간의 상호 운용성을 제공하는 라이브러리로, Py4J를 사용하면 파이썬 프로그램에서 자바 객체를 호출하거나, 자바에서 파이썬 객체를 호출할 수 있음.
- Spark는 기본적으로 Apache에서 만들었기 때문에, Java 기반 분산 컴퓨팅 엔진임. 그런데, Python 사용자들이 Spark를 사용할 수 있도록 API를 지원하는 형태임.
- **SparkContext 객체가 파이썬에서 생성될 때, Py4J를 통해 자바로 작성된 SparkContext와 연결되는 과정이 발생하기 때문에, Python으로 코드를 작성해도 동작할 수 있는 것임.**

### Spark에서 메모리는 어떻게 관리하는가?

- Reserved Memory
    - 예약된 영역으로, 시스템 프로세스나 기타 메모리 관련 Overhead를 처리하는데 사용
    - 300MB로 설정되어 있음.
- User Memory
    - Java Heap 메모리의 일부가 사용자 메모리로 활용됨.
    - RDD난 DataFrame 연산에서 발생하는 **중간 결과 / 사용자 정의 객체 / 내부 데이터 구조** 등을 저장하는데 사용
    - 일단 25%가 Default로 할당됨.
- Spark Memory
    - Execution Memory는 작업 중에 사용되는 메모리로써, `Shuffle / Join / Agg` 등의 중간 결과를 저장하는데 사용되는 메모리임.
    - Storage Memory는 RDD나 DataFrame을 저장하는데 사용하는 메모리로, `persist`() / `cache`() 메서드를 사용할 때 활용됨.
    - 75%가 Default로 할당됨.
- persist(`MEMORY_AND_DISK`)
    - 메모리와 디스크에 동시에 캐싱하는 방식
    - 메모리에만 저장한 상태에서 작업을 수행하다가 메모리가 부족하면, 캐시가 지워질 수 있는데, 이러한 경우에 재계산을 수행해야 하기 때문에 비효율적이다. 이러한 문제를 해결해줄 수 있는 것이 바로 `MEMORY_AND_DISK` 임

### Shuffle

- Shuffle 작업이란 여러 파티션에 분산되어 저장된 데이터 사이에 재배치가 필요한 상황에 발생하는 것으로, 주로 `groupby` / `join`과 같은 method를 사용할 때 발생함.
- Shuffle은 특정 파티션에서 또 다른 파티션으로 데이터가 “네트워크 이동” 해야하기 때문에, Cost가 상당히 큰 작업이고, 최적화를 위해서는 기피해야 함.

### Shuffle하는 이유 (원인)

- Data의 분포가 고르지 않는 (Skewing) 상태일 때.
- 특정 파티션에 데이터가 몰려있을 때
- 집계 연산(GroupBy, Join …)을 수행할 때
- 하나의 노드에서 캐싱한 데이터의 크기가 커질 때
- Spark는 기본적으로 실행할 노드가 있는 곳에 데이터를 가깝게 배치하려고 함(Data Locality).  그런데, 데이터가 이미 해당 노드에 저장되어 있지 않은 경우 작업 수행을 위해 데이터를 이동시켜야 하며, 이 과정에서 셔플링이 발생할 수 있음.

### Repartition / Coalesce

- Repartition()은 `전체 클러스터 간 shuffle을` 수행하여 파티션을 재분배 하는 과정임.
- Coalesce()는 `인접한 클러스터 간 shuffle`(정확한 표현으로는 인접한 partition 간의 Merge)을 수행하여 파티션을 재분배 하는 과정

### Data Skewing을 줄이는 방법

- 적절한 파티셔닝 전략
    - 특정 데이터의 Key 분포를 분석해서 분포가 고른 Key를 기준으로 partitioning을 수행
- sampling
    - 샘플링을 통해 특정 키가 많이 발생하는 문제를 식별할 수 있음.
    - 스큐된 키를 처리하기 위한 전략을 세울 수 있음.
- 집계
    - 사전 집계나, 부분 집계를 통해 스큐로 인한 오버헤드를 줄일 수 있음

### Splitting

- 큰 데이터 조각을 작은 데이터 조각 여러 개로 나누는 과정 (큰거 1개 col + 나머지 col)
- 데이터를 나눠서 병렬 처리할 수 있기 때문에  전체 작업 성능 향상에 도움이 됨.

### Salting

- 특정 키에 데이터 불균형이 발생하는 것을 인지했을 때, 인위적으로 key를 조작하여 데이터를 고르게 분산시키는 방법임.
- 기존의 key에 무작위 값을 추가하여 임의의 key를 만들고, 이를 분산시켜 처리함.
- 필요시에 다시 병합하여 작업을 수행하면 문제가 발생하지 않음.

### Broadcasting

- 작은 데이터 셋을 클러스터의 모든 노드로 전달하여 작업 성능을 최적화하는 기술
- 큰 데이터 셋과 조인 연산을 수행할 때, 작은 데이터셋을 모든 노드에 분산하여 처리하면 조인 작업을 빠르게 수행할 수 있음.
- 조인에서의 I/O 연산을 줄일 수 있기 때문에 처리 속도 측면에서 효과적임